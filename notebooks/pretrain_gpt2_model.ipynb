{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data on which we will train the model and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the text: 20479\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "print(\"Total number of characters in the text:\", len(raw_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure our special GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify configuration of small GPT-2 model\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, \n",
    "    \"context_length\": 256, #1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12, #number of attention heads\n",
    "    \"n_layers\": 12, #number of transformer blocks\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "# Compute the total params that are to be trained\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 123,822,336\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel()\n",
    "    for p in model.out_head.parameters())                   \n",
    "    )\n",
    "print(f\"Number of trainable parameters \"\n",
    "      f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight tying is essentially when the GPT-2 architecture reuses the weights from the token embedding layer in its output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 619.58 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params*4\n",
    "total_size_mb = total_size_bytes/(1024*1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text from an untrained GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you  Stores behavedaiden Refer launch Compos Burn wonderiterranean alliance\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you \"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model, idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"])\n",
    "\n",
    "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: 20479\n",
      "tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# We've already read in the verdict as raw_text\n",
    "total_characters = len(raw_text)\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "print(\"characters:\", total_characters)\n",
    "print(\"tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split raw_text into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 18431\n",
      "Validation data size: 2048\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n",
    "print(\"Training data size:\",len(train_data))\n",
    "print(\"Validation data size:\", len(val_data))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], #so totally non-overlapping\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], #so totally non-overlapping\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report initial training and validation losses on untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.986602677239311\n",
      "Validation loss: 10.981025695800781\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main: Training the model (10 epochs, AdamW, train_model_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss  9.690, Val loss  9.963\n",
      "Ep 1 (Step 000005): Train loss  8.049, Val loss  8.306\n",
      "Every effort moves you, the the the the the the the the the the the the the.                                   \n",
      "Ep 2 (Step 000010): Train loss  6.617, Val loss  7.034\n",
      "Ep 2 (Step 000015): Train loss  6.110, Val loss  6.578\n",
      "Every effort moves you, the, the, the, the, the, the, the the, the, the, the, the, the, the, the the, the, the, the, the, the, the, the, the, the, the\n",
      "Ep 3 (Step 000020): Train loss  5.737, Val loss  6.432\n",
      "Ep 3 (Step 000025): Train loss  5.600, Val loss  6.509\n",
      "Every effort moves you.                                                 \n",
      "Ep 4 (Step 000030): Train loss  5.644, Val loss  6.567\n",
      "Ep 4 (Step 000035): Train loss  5.069, Val loss  6.561\n",
      "Every effort moves you\"\"\"\"\"\"\"\"\" I had a a of the of the of the\"-- his the\" I had the of the of the of the of the of the of the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss  4.579, Val loss  6.382\n",
      "Every effort moves you know  \"I that he was his pictures--and I had been I had been--and it--and it--and it was his the picture--and it was his my elbow and I had the picture and he was his it was his\n",
      "Ep 6 (Step 000045): Train loss  4.197, Val loss  6.259\n",
      "Ep 6 (Step 000050): Train loss  3.843, Val loss  6.209\n",
      "Every effort moves you know to work, and pushed one of the to the fact of the fact of the fact of the fact of the fact of the fact to the fact of the fact of the fact.             \n",
      "Ep 7 (Step 000055): Train loss  3.266, Val loss  6.177\n",
      "Ep 7 (Step 000060): Train loss  2.796, Val loss  6.188\n",
      "Every effort moves you know,\" was not that my hostess was to the fact that, I had not to have to see it was not to have to see it was dead.\"                  \n",
      "Ep 8 (Step 000065): Train loss  2.129, Val loss  6.209\n",
      "Ep 8 (Step 000070): Train loss  1.808, Val loss  6.232\n",
      "Every effort moves you?\"  \"I my hostess was--and a good-century a and Mrs.                 \"--and I, the donkey. \"There were, I had\n",
      "Ep 9 (Step 000075): Train loss  1.405, Val loss  6.261\n",
      "Ep 9 (Step 000080): Train loss  1.117, Val loss  6.324\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me to me to have that, in the moment--as Jack himself, as once one had I had been the \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss  0.799, Val loss  6.332\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with his last word.        He laughed again, when, my his head to the donkey--if I may be pardoned the bull--that I found\n"
     ]
    }
   ],
   "source": [
    "## Main training loop\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the model has memorized the data because training data loss dropped while validation loss didn't drop nearly as much. This makes sense because our training set is very tiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the model in eval mode to turn off random components like dropout\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with his last word.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=20,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Scaling to introduce probabilistic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "G my surpriseed chair, his pictures-- toldas such purely\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and saving model weights in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current trained model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model to a new GPT instance\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the optimizer state_dict contents\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_builder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
